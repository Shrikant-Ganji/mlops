# Week 2: Experiment Tracking and MLflow

This week focuses on experiment tracking, reproducibility, and managing machine learning workflows using MLflow. The content is part of the MLOps Zoomcamp 2025 series.

## Homework 2 Overview

This week's homework guides you through:

1. **Installing and verifying MLflow**
2. **Preprocessing NYC taxi trip data using scripts**
3. **Training a Random Forest model with MLflow autologging**
4. **Launching the MLflow Tracking Server (locally or in Codespaces)**
5. **Hyperparameter tuning**
6. **Registering the best model in the MLflow Model Registry**

The notebook and scripts automate experiment management and model tracking.

## Directory Structure

- `homework2.ipynb`  
  Jupyter notebook for Week 2 assignments and hands-on exercises.  
  - Walks through MLflow installation, data preprocessing, training, experiment tracking, and registry tasks.

- `homework2/`  
  Contains supporting scripts:
  - `preprocess_data.py`: Preprocesses raw data and saves processed datasets.
  - `train.py`: Trains a RandomForestRegressor, logs parameters and metrics to MLflow.
  - `hpo.py`, `register_model.py`: (if present) Used for hyperparameter optimization and model registration.

- `mlflow-env/`  
  Environment setup or configuration files for MLflow.

- `mlflow.db`  
  SQLite database used by MLflow to store experiment metadata.

- `mlruns/`  
  Directory where MLflow stores run data, metrics, parameters, artifacts, and logs.

- `output/`  
  Output files generated during the experiments (`train.pkl`, `val.pkl`, `test.pkl`, `dv.pkl`).

- `output.log`  
  Log file capturing outputs from scripts or MLflow runs.

- `data/`  
  Contains datasets used for the experiments.

## Main Steps (from the Notebook & Scripts)

1. **Install MLflow & Check Version**
   ```python
   !pip install mlflow --quiet
   import mlflow
   print(mlflow.__version__)
   !mlflow --version
   ```

2. **Preprocess Data**
   - Download NYC taxi data (Parquet format) into `data/`.
   - Run preprocessing:
     ```bash
     python homework2/preprocess_data.py --raw_data_path ./data --dest_path ./output
     ```
   - Outputs `train.pkl`, `val.pkl`, `test.pkl`, and `dv.pkl` in `output/`.

3. **Train Model with Autologging**
   ```bash
   python homework2/train.py
   ```
   - Random Forest model, autologged with MLflow.

4. **Launch the Tracking Server (in Codespaces)**
   ```bash
   mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts --host 0.0.0.0 --port 5000
   ```
   - In Codespaces, forward port 5000 to view MLflow UI.

5. **Hyperparameter Tuning & Model Registry**
   - (If scripts present) Run:
     ```bash
     python homework2/hpo.py
     python homework2/register_model.py
     ```

## Using GitHub Codespaces

1. **Open in Codespace**  
   Click the `Code` button on the repository and select **Open with Codespaces** to start a new Codespace.

2. **Environment Setup**  
   Your Codespace will automatically use the repository's dev container if present.  
   If not, install dependencies as follows (in the terminal pane inside Codespaces):

   ```bash
   pip install -r mlflow-env/requirements.txt
   ```

   or set up the environment as specified in `mlflow-env/`.

3. **Start MLflow UI**  
   In the Codespace terminal, run:

   ```bash
   mlflow ui --host 0.0.0.0 --port 5000
   ```

   > **Note:**  
   > Codespaces exposes forwarded ports in the "Ports" tab.  
   > Click the "Ports" tab, find port 5000, and click the "Open in Browser" link to access the MLflow UI.

4. **Run the Notebook**  
   Codespaces comes with Jupyter pre-installed. Open `homework2.ipynb` directly from the file explorer and run the cells.

## Resources

- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [MLOps Zoomcamp](https://github.com/DataTalksClub/mlops-zoomcamp)
- [GitHub Codespaces Docs](https://docs.github.com/en/codespaces)
- [Homework instructions](https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/cohorts/2025/02-experiment-tracking/homework.md)

## Notes

- The `mlflow.db` and `mlruns/` directories are auto-generated by MLflow.
- Ensure you do not commit sensitive data or large artifacts.
- For any issues, refer to the logs in `output.log`.

---

Happy Experimenting in the Cloud!
